
#Loss function
https://www.cnblogs.com/guoyaohua/p/9217206.html

#Loss function
https://blog.csdn.net/sinat_36972314/article/details/82850475


#activation function
https://blog.csdn.net/chenxaioxue/article/details/82317363


#activation function
https://www.cnblogs.com/jokerjason/p/9436117.html

#梯度下降算法
https://www.jianshu.com/p/c7e642877b0e

Adam算法
https://www.cnblogs.com/yifdu25/p/8183587.html

sigmoid,tanh,Relu
https://blog.csdn.net/u011684265/article/details/78039280

#LSTM，RNN，
https://www.cnblogs.com/pinard/p/6519110.html

前向，反向传播
https://www.cnblogs.com/wlzy/p/7751297.html
